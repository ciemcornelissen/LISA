@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = ICCV,
pages = {234--778},
year = 2005
}

@article{HSIreview, title={Hyperspectral imaging and its applications: A review}, volume={10}, ISSN={2405-8440}, DOI={10.1016/j.heliyon.2024.e33208}, number={12}, journal={Heliyon}, publisher={Heliyon}, author={Bhargava, Anuja and Sachdeva, Ashish and Sharma, Kulbhushan and Alsharif, Mohammed H. and Uthansakul, Peerapong and Uthansakul, Monthippa}, year={2024}, pages={e33208} }

@article{ChemicalSoil,
title = {Estimation of soil properties using Hyperspectral imaging and Machine learning},
journal = {Smart Agricultural Technology},
volume = {10},
pages = {100790},
year = {2025},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2025.100790},
url = {https://www.sciencedirect.com/science/article/pii/S2772375525000243},
author = {Eirini Chlouveraki and Nikolaos Katsenios and Aspasia Efthimiadou and Erato Lazarou and Kalliopi Kounani and Eleni Papakonstantinou and Dimitrios Vlachakis and Aikaterini Kasimati and Ioannis Zafeiriou and Borja Espejo-Garcia and Spyros Fountas},
keywords = {Hyperspectral, Soil health monitoring, Collinearity, Feature extraction},
abstract = {Hyperspectral sensors generate vast arrays of spectral bands, offering unprecedented opportunities to estimate soil properties quickly and cost-effectively when integrated into the appropriate machine learning (ML) pipeline. However, the high dimensionality and collinearity inherent to these spectra pose challenges for precise property detection, often leading to poor generalization. This study investigates the combined use of feature extraction and selection techniques to refine the input space for four distinct modeling approaches— Principal Component Regression (PCR), Automatic Relevance Determination (ARD), Partial Least Squares Regression (PLSR), and Multi-Layer Perceptrons (MLP)—to accurately predict soil properties while reducing the need for expensive laboratory chemical analyses. To this end, all basic soil properties were analyzed, including pH, electrical conductivity (EC), soil organic matter (SOM), total carbonates percentage (total CaCO3 %), macronutrients (total nitrogen (N), phosphorus (P), potassium (K), calcium (Ca), and magnesium (Mg)), and micronutrients (iron (Fe), copper (Cu), manganese (Mn), zinc (Zn), and boron (B)). The proposed methodology first applies feature selection — F-test, Mutual Information, and permutation — and dimensionality reduction methods — Principal Component Analysis (PCA) and Uniform Manifold Approximation and Projection (UMAP) — to extract informative spectral features. These steps aim to mitigate redundancy and noise, enhancing the model's generalization. Results showed that Mg (R² = 0.73), total CaCO3 % (R² = 0.74), B (R² = 0.67), and Fe (R² = 0.57) could lead to promising performances with low overfitting. Finally, using neural-based regressors (MLPs) improved the performances of PCR and PLS in several cases, opening the exploration of novel neural-based solutions in future soil property analysis work.}
}

@article{chemicalcheese,
title = {Application of near-infrared hyperspectral imaging for determination of cheese chemical composition},
journal = {Journal of Food Composition and Analysis},
volume = {127},
pages = {105994},
year = {2024},
issn = {0889-1575},
doi = {https://doi.org/10.1016/j.jfca.2024.105994},
url = {https://www.sciencedirect.com/science/article/pii/S0889157524000280},
author = {Caroline Bilhar Karaziack and Cristiane Vidal and Celio Pasquini and Douglas Fernandes Barbin and Walkiria Hanada Viotto},
keywords = {Chemical imaging, Partial least squares regression, Mozzarela, Coalho, Prediction, Dairy},
abstract = {Cheeses vary in chemical composition as they have different applications according to the technological features; some hard cheeses are consumed fresh while melting is a desirable characteristic for others. The conventional reference methods for determination of cheese composition and quality are accurate, but include physical-chemical analyses that are time-consuming and require use of chemical reagents. The objective of this work was to apply near-infrared hyperspectral imaging (NIR-HSI) as a fast method for prediction and visualization of spatial distribution of chemical composition of different types of cheeses (mozzarela, requeijão do norte, minas meia cura, coalho, prato). Moisture, fat, protein, and free oil were measured, and used as reference for prediction models, while spectral information extracted from images in the range of 928–2524 nm were used as predictors. Partial Least Squares (PLS) regression models were built with full spectra and using only few selected regions with higher importance, which were applied to the images to build chemical maps and visualize the spatial variation of the cheese composition. The regression models were able to predict moisture (R2P = 0.92, RMSEP = 1.1%); fat (R2P = 0.84, RMSEP = 1.5%); protein (R2P = 0.80, RMSEP = 1.8%); and free oil (R2P =0.64, RMSEP = 0.5%) for an external set of samples, while requiring a small number of latent variables (LVs) (between 3 and 4). The chemical maps allowed visualization of the spatial distribution for each attribute, demonstrating that the composition may vary within sample. The study demonstrated the potential of NIR-HSI for the determination of cheese composition and possible application to cheese quality control.}
}
@inproceedings{mypaper,
  author       = {Ciem Cornelissen and
                  Sam Leroux and
                  Pieter Simoens},
  title        = {Adaptive Clustering for Efficient Phenotype Segmentation of {UAV}
                  Hyperspectral Data},
  booktitle    = {{IEEE/CVF} Winter Conference on Applications of Computer Vision, {WACV}
                  2025 - Workshops, Tucson, AZ, USA, February 28 - March 4, 2025},
  pages        = {422--431},
  publisher    = {{IEEE}},
  year         = {2025},
  url          = {https://doi.org/10.1109/WACVW65960.2025.00053},
  doi          = {10.1109/WACVW65960.2025.00053},
  timestamp    = {Wed, 28 May 2025 09:03:47 +0200},
  biburl       = {https://dblp.org/rec/conf/wacv/CornelissenLS25.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@Article{diverseApplications,
AUTHOR = {Cheng, Ming-Fang and Mukundan, Arvind and Karmakar, Riya and Valappil, Muhamed Adil Edavana and Jouhar, Jumana and Wang, Hsiang-Chen},
TITLE = {Modern Trends and Recent Applications of Hyperspectral Imaging: A Review},
JOURNAL = {Technologies},
VOLUME = {13},
YEAR = {2025},
NUMBER = {5},
ARTICLE-NUMBER = {170},
URL = {https://www.mdpi.com/2227-7080/13/5/170},
ISSN = {2227-7080},
ABSTRACT = {Hyperspectral imaging (HSI) is an advanced imaging technique that captures detailed spectral information across multiple fields. This review explores its applications in counterfeit detection, remote sensing, agriculture, medical imaging, cancer detection, environmental monitoring, mining, mineralogy, and food processing, specifically highlighting significant achievements from the past five years, providing a timely update across several fields. It also presents a cross-disciplinary classification framework to systematically categorize applications in medical, agriculture, environment, and industry. In counterfeit detection, HSI identified fake currency with high accuracy in the 400–500 nm range and achieved a 99.03% F1-score for counterfeit alcohol detection. Remote sensing applications include hyperspectral satellites, which improve forest classification accuracy by 50%, and soil organic matter, with the prediction reaching R2 = 0.6. In agriculture, the HSI-TransUNet model achieved 86.05% accuracy for crop classification, and disease detection reached 98.09% accuracy. Medical imaging benefits from HSI’s non-invasive diagnostics, distinguishing skin cancer with 87% sensitivity and 88% specificity. In cancer detection, colorectal cancer identification reached 86% sensitivity and 95% specificity. Environmental applications include PM2.5 pollution detection with 85.93% accuracy and marine plastic waste detection with 70–80% accuracy. In food processing, egg freshness prediction achieved R2 = 91%, and pine nut classification reached 100% accuracy. Despite its advantages, HSI faces challenges like high costs and complex data processing. Advances in artificial intelligence and miniaturization are expected to improve accessibility and real-time applications. Future advancements are anticipated to concentrate on the integration of deep learning models for automated feature extraction and decision-making in hyperspectral imaging analysis. The development of lightweight, portable HSI devices will enable more on-site applications in agriculture, healthcare, and environmental monitoring. Moreover, real-time processing methods will enhance efficiency for field deployment. These improvements seek to enhance the accessibility, practicality, and efficacy of HSI in both industrial and clinical environments.},
DOI = {10.3390/technologies13050170}
}

@article{dimensionReduction,
title = {Strategies for dimensionality reduction in hyperspectral remote sensing: A comprehensive overview},
journal = {The Egyptian Journal of Remote Sensing and Space Sciences},
volume = {27},
number = {1},
pages = {82-92},
year = {2024},
issn = {1110-9823},
doi = {https://doi.org/10.1016/j.ejrs.2024.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S111098232400005X},
author = {Radhesyam Vaddi and B.L.N. {Phaneendra Kumar} and Prabukumar Manoharan and L. Agilandeeswari and V. Sangeetha},
keywords = {Hyperspectral, Dimensionality reduction, Feature extraction, Band selection, Classification},
abstract = {The technological advancements in spectroscopy give rise to acquiring data about different materials on earth's surface which can be utilized in a variety of potential applications. But, the hundreds of spectral bands are generally equipped with highly correlated information with limited training samples. This will degrade the Hyperspectral Image (HSI) classification accuracy. So Dimensionality Reduction (DR) has become inevitable and necessary step need to incorporate before HSI classification. The main contribution of this work lies in comparative study and review on dimensionality reduction techniques for Hyperspectral remote sensing image classification. The related challenges and research directions are also discussed. This study will help the researchers in the Hyperspectral remote sensing community to choose the appropriate DR technique for classification which can be useful in various real time applications.}
}

@article{robustFeatures, title={Enhancing feature learning of hyperspectral imaging using shallow autoencoder by adding parallel paths encoding}, volume={15}, ISSN={2045-2322}, DOI={10.1038/s41598-025-01758-w}, number={1}, journal={Scientific Reports}, publisher={Scientific Reports}, author={Noor Asmat, Bibi and Syed Muhammad Bilal, Hafiz and Uddin, M. Irfan and Khalid Karim, Faten and Mostafa, Samih M. and Varela-Aldás, José}, year={2025} }

@article{lightingConditions, title={Eliminating Temporal Illumination Variations in Whisk-broom Hyperspectral Imaging}, volume={130}, ISSN={0920-5691}, DOI={10.1007/s11263-022-01587-8}, number={5}, journal={International Journal of Computer Vision}, publisher={International Journal of Computer Vision}, author={Funatomi, Takuya and Ogawa, Takehiro and Tanaka, Kenichiro and Kubo, Hiroyuki and Caron, Guillaume and Mouaddib, El Mustapha and Matsushita, Yasuyuki and Mukaigawa, Yasuhiro}, year={2022}, pages={1310–1324} }

@article{atmosphericCorrections, title={Fast Atmospheric Correction Method for Hyperspectral Data}, volume={10}, ISSN={2072-4292}, DOI={10.3390/rs10111698}, number={11}, journal={Remote Sensing}, publisher={Remote Sensing}, author={Katkovsky, Leonid V. and Martinov, Anton O. and Siliuk, Volha A. and Ivanov, Dimitry A. and Kokhanovsky, Alexander A.}, year={2018}, pages={1698} }

@article{labToField, title={Evaluation of rice bacterial blight severity from lab to field with hyperspectral imaging technique}, volume={13}, ISSN={1664-462X}, DOI={10.3389/fpls.2022.1037774}, journal={Frontiers in Plant Science}, publisher={Frontiers in Plant Science}, author={Bai, Xiulin and Zhou, Yujie and Feng, Xuping and Tao, Mingzhu and Zhang, Jinnuo and Deng, Shuiguang and Lou, Binggan and Yang, Guofeng and Wu, Qingguan and Yu, Li and et al.}, year={2022} }

@article{domainShift,
title = {Cross-domain hyperspectral image classification},
journal = {Pattern Recognition},
volume = {168},
pages = {111836},
year = {2025},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2025.111836},
url = {https://www.sciencedirect.com/science/article/pii/S0031320325004960},
author = {Zhiyu Jiang and Jianing Li and Shijie Xu and Zhuozhao Liu and Dandan Ma and Qi Wang and Yuan Yuan},
keywords = {Hyperspectral image classification, Cross-domain, Label-limited classification, Label-free classification, Unknown-label classification, Sample-free classification},
abstract = {Cross-domain hyperspectral image (HSI) classification represents a significant and complex challenge within the realm of remote sensing. HSIs obtained from diverse domains, captured at different times and under varying environmental conditions, frequently display substantial discrepancies. These variations can lead to a marked deterioration in the efficacy of classification algorithms when they are applied to novel scenes, thereby constraining the practical implementation of existing technologies. This paper presents a thorough review of the challenges associated with cross-domain HSI classification, examining the issues from the perspectives of problem definition, methodology, datasets, and applications. Initially, we introduce an innovative framework for cross-domain hyperspectral image classification tasks, organizing current advancements into four distinct sub-tasks: label-limited, label-free, unknown-label, and sample-free. For each sub-task, we systematically summarize recent technical advancements and notable methodologies. Subsequently, we conduct a comparative analysis of state-of-the-art techniques for these tasks, utilizing several widely recognized datasets to underscore current technological progress and trends. Additionally, we adopt a novel approach to address the emerging challenge of cross-domain data heterogeneity, specifically focusing on spectral heterogeneity arising from differences in imaging devices as a case study, which provides valuable insights into this issue. Finally, we outline the existing challenges and propose promising future research directions in cross-domain HSI classification, with the aim of stimulating further investigation and enhancing the applicability of HSI classification techniques in practical scenarios.}
}
@article{realWorldChallenges,
title = {Robustness of hyperspectral imaging and PLSR model predictions of intramuscular fat in lamb M. longissimus lumborum across several flocks and years},
journal = {Meat Science},
volume = {179},
pages = {108492},
year = {2021},
issn = {0309-1740},
doi = {https://doi.org/10.1016/j.meatsci.2021.108492},
url = {https://www.sciencedirect.com/science/article/pii/S0309174021000681},
author = {S. Hitchman and M.P.F. Loeffen and M.M. Reis and C.R. Craigie},
keywords = {IMF%, Lamb, Hyperspectral imaging, PLS model robustness, NIR spectroscopy},
abstract = {The percentage of intramuscular fat content of lamb meat is a key index of consumer acceptability. Hyperspectral imaging is a potential technique for in-line measurements of intramuscular fat in fresh meat. However, little work has been conducted to investigate the robustness of hyperspectral imaging data and associated multivariate models over time. Fifteen trials consisting of eight independent flocks across five years were used to quantify robustness of partial least squares regression (PLSR) models developed using data collected with the same imaging system. Two models were developed; one using data from the first year of the trials, and a progressive model that cumulatively includes data in chronological order. The two models performed similarly, in terms of the coefficient of determination (R2), standard error of prediction (SEP) and bias, when experimental conditions were consistent. However, under varying imaging conditions, the progressive model was able to account for this variability resulting in higher R2 and lower SEP.}
}

@article{whiteReference,
author = {Shaikh, Muhammad Saad and Jaferzadeh, Keyvan and Thörnberg, Benny and Casselgren, Johan},
year = {2021},
month = {05},
pages = {3738},
title = {Calibration of a Hyper-Spectral Imaging System Using a Low-Cost Reference},
volume = {21},
journal = {Sensors},
doi = {10.3390/s21113738}
}
@article{whiteRefLimitations,
title = {Practical recommendations and limitations for pushbroom hyperspectral imaging of tree stems},
journal = {Remote Sensing of Environment},
volume = {298},
pages = {113837},
year = {2023},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2023.113837},
url = {https://www.sciencedirect.com/science/article/pii/S0034425723003887},
author = {Jussi Juola and Aarne Hovi and Miina Rautiainen},
keywords = {Forest, Reflectance, Spectra, Bark, Hyperspectral, Field spectroscopy, Imaging},
abstract = {In this short communication, we present a pilot study testing a new close-range sensing technology – a portable, pushbroom hyperspectral camera – in varying field conditions in forests. We evaluate how measurement conditions affect the in situ collection of stem bark spectra. In situ spectral libraries of woody elements are needed in, e.g., physically-based remote sensing applications, biodiversity mapping, and 3D vegetation modeling. Recent technological advancements bring portable and close-range capable sensors, such as small pushbroom imaging spectrometers, for consumer and research use. However, it is important to investigate the strengths and limitations of sensors utilizing pushbroom technology. Spectral measurements under forest canopies are challenging due to varying illumination conditions, which can have a significant effect on the quality of the data. We acquired hyperspectral reflectance images of Norway spruce (Picea abies (L.) Karst), Scots pine (Pinus sylvestris L.), and silver birch (Betula pendula Roth) stem bark directly in the forest. For each tree we collected reflectance images at 30-minute intervals throughout a day from a fixed view angle. The most significant change in the measured spectra occurred due to spatially varying irradiance between the white reference panel and the bark surface. The spatial variation of irradiance had the largest effect on data quality in visible and red-edge regions, and the smallest in near-infrared. In non-diffuse conditions, changes in irradiance were often unpredictable as clouds or canopy elements moved in and out of the direct solar beams. Diffuse overcast days with clouds can extend the time window for measurements, making it a practical choice for acquiring hyperspectral images of stem bark. We concluded that with a well-planned measurement set-up it is possible to improve the precision of in situ collected spectra of stem bark.}
}


@Article{needForNotWhiteReference,
AUTHOR = {Ma, Dongdong and Rehman, Tanzeel U. and Zhang, Libo and Maki, Hideki and Tuinstra, Mitchell R. and Jin, Jian},
TITLE = {Modeling of Environmental Impacts on Aerial Hyperspectral Images for Corn Plant Phenotyping},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2520},
URL = {https://www.mdpi.com/2072-4292/13/13/2520},
ISSN = {2072-4292},
ABSTRACT = {Aerial imaging technologies have been widely applied in agricultural plant remote sensing. However, an as yet unexplored challenge with field imaging is that the environmental conditions, such as sun angle, cloud coverage, temperature, and so on, can significantly alter plant appearance and thus affect the imaging sensor’s accuracy toward extracting plant feature measurements. These image alterations result from the complicated interaction between the real-time environments and plants. Analysis of these impacts requires continuous monitoring of the changes through various environmental conditions, which has been difficult with current aerial remote sensing systems. This paper aimed to propose a modeling method to comprehensively understand and model the environmental influences on hyperspectral imaging data. In 2019, a fixed hyperspectral imaging gantry was constructed in Purdue University’s research farm, and over 8000 repetitive images of the same corn field were taken with a 2.5 min interval for 31 days. Time-tagged local environment data, including solar zenith angle, solar irradiation, temperature, wind speed, and so on, were also recorded during the imaging time. The images were processed for phenotyping data, and the time series decomposition method was applied to extract the phenotyping data variation caused by the changing environments. An artificial neural network (ANN) was then built to model the relationship between the phenotyping data variation and environmental changes. The ANN model was able to accurately predict the environmental effects in remote sensing results, and thus could be used to effectively eliminate the environment-induced variation in the phenotyping features. The test of the normalized difference vegetation index (NDVI) calculated from the hyperspectral images showed that variance in NDVI was reduced by 79%. A similar performance was confirmed with the relative water content (RWC) predictions. Therefore, this modeling method shows great potential for application in aerial remote sensing applications in agriculture, to significantly improve the imaging quality by effectively eliminating the effects from the changing environmental conditions.},
DOI = {10.3390/rs13132520}
}





@ARTICLE{Feng2025-lp,
  title     = "{S4DL}: Shift-sensitive spatial-spectral disentangling learning
               for hyperspectral image unsupervised domain adaptation",
  author    = "Feng, Jie and Zhang, Tianshu and Zhang, Junpeng and Shang,
               Ronghua and Dong, Weisheng and Shi, Guangming and Jiao, Licheng",
  abstract  = "Unsupervised domain adaptation (UDA) techniques, extensively
               studied in hyperspectral image (HSI) classification, aim to use
               labeled source domain data and unlabeled target domain data to
               learn domain invariant features for cross-scene classification.
               Compared to natural images, numerous spectral bands of HSIs
               provide abundant semantic information, but they also increase
               the domain shift significantly. In most existing methods, both
               explicit alignment and implicit alignment simply align feature
               distribution, ignoring domain information in the spectrum. We
               noted that when the spectral channel between source and target
               domains is distinguished obviously, the transfer performance of
               these methods tends to deteriorate. Additionally, their
               performance fluctuates greatly owing to the varying domain
               shifts across various datasets. To address these problems, a
               novel shift-sensitive spatial-spectral disentangling learning
               (S4DL) approach is proposed. In S4DL, gradient-guided
               spatial-spectral decomposition (GSSD) is designed to separate
               domain-specific and domain-invariant representations by
               generating tailored masks under the guidance of the gradient
               from domain classification. A shift-sensitive adaptive monitor
               is defined to adjust the intensity of disentangling according to
               the magnitude of domain shift. Furthermore, a reversible neural
               network is constructed to retain domain information that lies
               not only in semantic but also the shallow-level detailed
               information. Extensive experimental results on several
               cross-scene HSI datasets consistently verified that S4DL is
               better than the state-of-the-art UDA methods. Our source code
               will be available at
               https://github.com/xdu-jjgs/IEEE\_TNNLS\_S4DL.",
  journal   = "IEEE Trans. Neural Netw. Learn. Syst.",
  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
  volume    = "PP",
  pages     = "1--15",
  month     =  apr,
  year      =  2025,
  copyright = "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html",
  language  = "en"
}

@ARTICLE{dimensionality,
  title     = "{S4DL}: Shift-sensitive spatial-spectral disentangling learning
               for hyperspectral image unsupervised domain adaptation",
  author    = "Feng, Jie and Zhang, Tianshu and Zhang, Junpeng and Shang,
               Ronghua and Dong, Weisheng and Shi, Guangming and Jiao, Licheng",
  abstract  = "Unsupervised domain adaptation (UDA) techniques, extensively
               studied in hyperspectral image (HSI) classification, aim to use
               labeled source domain data and unlabeled target domain data to
               learn domain invariant features for cross-scene classification.
               Compared to natural images, numerous spectral bands of HSIs
               provide abundant semantic information, but they also increase
               the domain shift significantly. In most existing methods, both
               explicit alignment and implicit alignment simply align feature
               distribution, ignoring domain information in the spectrum. We
               noted that when the spectral channel between source and target
               domains is distinguished obviously, the transfer performance of
               these methods tends to deteriorate. Additionally, their
               performance fluctuates greatly owing to the varying domain
               shifts across various datasets. To address these problems, a
               novel shift-sensitive spatial-spectral disentangling learning
               (S4DL) approach is proposed. In S4DL, gradient-guided
               spatial-spectral decomposition (GSSD) is designed to separate
               domain-specific and domain-invariant representations by
               generating tailored masks under the guidance of the gradient
               from domain classification. A shift-sensitive adaptive monitor
               is defined to adjust the intensity of disentangling according to
               the magnitude of domain shift. Furthermore, a reversible neural
               network is constructed to retain domain information that lies
               not only in semantic but also the shallow-level detailed
               information. Extensive experimental results on several
               cross-scene HSI datasets consistently verified that S4DL is
               better than the state-of-the-art UDA methods. Our source code
               will be available at
               https://github.com/xdu-jjgs/IEEE\_TNNLS\_S4DL.",
  journal   = "IEEE Trans. Neural Netw. Learn. Syst.",
  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
  volume    = "PP",
  pages     = "1--15",
  month     =  apr,
  year      =  2025,
  copyright = "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html",
  language  = "en"
}

@article{hsiGrape,
title = {In situ grape ripeness estimation via hyperspectral imaging and deep autoencoders},
journal = {Computers and Electronics in Agriculture},
volume = {212},
pages = {108098},
year = {2023},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2023.108098},
url = {https://www.sciencedirect.com/science/article/pii/S0168169923004866},
author = {Nikolaos L. Tsakiridis and Nikiforos Samarinas and Stylianos Kokkas and Eleni Kalopesa and Nikolaos V. Tziolas and George C. Zalidis},
keywords = {Dissolved solids, VNIR, Vis–NIR, Grape cultivars, Deep learning},
abstract = {The estimation of the grapes’ maturity in the field using non-destructive techniques is of high interest for the high-valued vinified grapes, particularly towards the development of fully automated agrobots that perform selective harvesting operations. Whereas infrared spectroscopy has been employed using point spectrometers in the laboratory and in the field, imaging spectrometers have mainly been tested in controlled laboratory conditions due to issues with varying illumination. In this paper, the application of the autoencoder framework is proposed, which is employed to transform the raw recorded spectra, regardless of illumination conditions, into standardized reflectance spectra; thus addressing the inherent difficulties which hamper the direct application of hyperspectral imaging in the field. To validate the methodology, the sugar content (∘Brix) of four grape varieties, namely Chardonnay, Malagouzia, Sauvignon-Blanc, and Syrah, is estimated. Two different autoencoder architectures are examined: deep fully-connected (DAE) and deep convolutional autoencoders (DCAE), while the estimation of sugar content takes place using as input both from the encoded (latent) space and from the autoencoders’ output, i.e., the transformed standardized spectra. The use of multiple spectral pre-treatments is further examined to enhance the accuracy of prediction. Despite that DAE and DCAE showcase comparable similarity metrics, DCAE statistically outperforms DAE when using both the encoded space and the autoencoders’ output, attesting to the suitability of the convolutional autoencoder framework. On the other hand, there is no statistical significant difference when employing multiple input pre-treatments. The accuracy of estimation (mean RMSE 1.83 ∘Brix, R2 0.70, RPIQ 2.43) is comparable to other studies that directly work with standardized reflectance spectra in laboratory conditions.}
}

@article{hsigrape2,
title = {On-the-go table grape ripeness estimation via proximal snapshot hyperspectral imaging},
journal = {Computers and Electronics in Agriculture},
volume = {226},
pages = {109354},
year = {2024},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2024.109354},
url = {https://www.sciencedirect.com/science/article/pii/S0168169924007452},
author = {Riccardo Bertoglio and Manuel Piliego and Paolo Guadagna and Matteo Gatti and Stefano Poni and Matteo Matteucci},
keywords = {Hyperspectral imaging, Total soluble solids, Anthocyanins, Ripeness, Table grape, PLS regression},
abstract = {The monitoring of grapes for ripeness estimation is a practice that enables fruit harvesting at the optimal time. Hyperspectral Imaging (HSI) represents a non-destructive and high-throughput alternative to traditional laboratory analyses. Current literature approaches perform hyperspectral measurements using line scan sensors or low-resolution static snapshot cameras, which hinder a fast per-bunch ripeness characterization. We propose a framework for on-the-go collection and processing of proximal snapshot hyperspectral images to estimate single bunch ripeness parameters. Focusing on table grapes (Vitis vinifera L. cv. Red Globe), we collected images under natural illumination with a hyperspectral camera (500–900 nm) mounted on a moving vehicle in an experimental block sited in Piacenza, Italy. We investigated images collected in August and September 2021 representing two ripening stages. The composition of the imaged grape bunches was determined through laboratory chemical analyses to predict Total Soluble Solids (TSS) and anthocyanin concentration. The images were pre-processed via multimodal image registration to correct the unalignment of bands due to the vehicle motion, and the single bunches were automatically identified on false RGB images through a Mask Region-Convolutional Neural Network (Mask R-CNN) instance segmentation network. The mean spectra of the bunches were used as input features of a Partial Least Squares Regression (PLSR) model to predict the chemical parameters at single bunch and whole vine scales. The regression model of TSS had an R2 (10-fold nested cross-validation) of 0.75 and 0.85 on a per-bunch and per-vine basis, respectively. The regression model of anthocyanin had an R2 of 0.68 and 0.49 on a per-bunch and per-vine basis, respectively. The results suggest the potential of using snapshot hyperspectral images for high-throughput analysis of a per-bunch grape ripeness estimation. The method described in this study could give valuable information to improve grape ripening monitoring and management of harvest operations and even allow for precise and automated robotic harvesting.}
}
@Article{portableHSI,
AUTHOR = {Podlesnykh, Ivan and Kovalev, Michael and Platonov, Pavel},
TITLE = {Towards the Future of Ubiquitous Hyperspectral Imaging: Innovations in Sensor Configurations and Cost Reduction for Widespread Applicability},
JOURNAL = {Technologies},
VOLUME = {12},
YEAR = {2024},
NUMBER = {11},
ARTICLE-NUMBER = {221},
URL = {https://www.mdpi.com/2227-7080/12/11/221},
ISSN = {2227-7080},
ABSTRACT = {Hyperspectral imaging is currently under active development as a method for remote sensing, environmental monitoring and biomedical diagnostics. The development of hyperspectral sensors is aimed at their miniaturization and reducing the cost of components for the purpose of the widespread use of such devices on unmanned aerial vehicles and satellites. In this review, we present a broad overview of recent work on the development of hyperspectral devices’ configurations, studies aimed at modifying sensors and the possibility of reducing the cost of components of such devices. In addition, we will present the main trends in the development of hyperspectral device configurations for ubiquitous applications.},
DOI = {10.3390/technologies12110221}
}



@article{precisionAgri,
title = {A systematic review of hyperspectral imaging in precision agriculture: Analysis of its current state and future prospects},
journal = {Computers and Electronics in Agriculture},
volume = {222},
pages = {109037},
year = {2024},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2024.109037},
url = {https://www.sciencedirect.com/science/article/pii/S0168169924004289},
author = {Billy G. Ram and Peter Oduor and C. Igathinathane and Kirk Howatt and Xin Sun},
keywords = {Hyperspectral, Precision agriculture, Data analysis, Real-time, Image analysis},
abstract = {Hyperspectral sensor adaptability in precision agriculture to digital images is still at its nascent stage. Hyperspectral imaging (HSI) is data rich in solving agricultural problems like disease detection, weed detection, stress detection, crop monitoring, nutrient application, soil mineralogy, yield estimation, and sorting applications. With modern precision agriculture, the challenge now is to bring these applications to the field for real-time solutions, where machines are enabled to conduct analyses without expert supervision and communicate the results to users for better management of farmlands; a necessary step to gain complete autonomy in agricultural farmlands. Significant advancements in HSI technology for precision agriculture are required to fully realize its potential. As a wide-ranging collection of the status of HSI and analysis in precision agriculture is lacking, this review endeavors to provide a comprehensive overview of the recent advancements and trends of HSI in precision agriculture for real-time applications. In this study, a systematic review of 163 scientific articles published over the past twenty years (2003–2023) was conducted. Of these, 97 were selected for further analysis based on their relevance to the topic at hand. Topics include conventional data preprocessing techniques, hyperspectral data acquisition, data compression methods, and segmentation methods. The hardware implementation of field-programmable gate arrays (FPGAs) and graphics processing units (GPUs) for high-speed data processing and application of machine learning and deep learning technologies were explored. This review highlights the potential of HSI as a powerful tool for precision agriculture, particularly in real-time applications, discusses limitations, and provides insights into future research directions.}
}


@Article{grape_1,
AUTHOR = {Lyu, Hongyi and Grafton, Miles and Ramilan, Thiagarajah and Irwin, Matthew and Sandoval, Eduardo},
TITLE = {Hyperspectral Imaging Spectroscopy for Non-Destructive Determination of Grape Berry Total Soluble Solids and Titratable Acidity},
JOURNAL = {Remote Sensing},
VOLUME = {16},
YEAR = {2024},
NUMBER = {10},
ARTICLE-NUMBER = {1655},
URL = {https://www.mdpi.com/2072-4292/16/10/1655},
ISSN = {2072-4292},
ABSTRACT = {Wine grape quality heavily influences the price received for a product. Hyperspectral imaging has the potential to provide a non-destructive technique for predicting various enological parameters. This study aims to explore the feasibility of applying hyperspectral imaging to measure the total soluble solids (TSS) and titratable acidity (TA) in wine grape berries. A normalized difference spectral index (NDSI) spectral preprocessing method was built and compared with the conventional preprocessing method: multiplicative scatter correction and Savitzky–Golay smoothing (MSC+SG). Different machine learning models were built to examine the performance of the preprocessing methods. The results show that the NDSI preprocessing method demonstrated better performance than the MSC+SG preprocessing method in different classification models, with the best model correctly classifying 93.8% of the TSS and 84.4% of the TA. In addition, the TSS can be predicted with moderate performance using support vector regression (SVR) and MSC+SG preprocessing with a root mean squared error (RMSE) of 0.523 °Brix and a coefficient of determination (R2) of 0.622, and the TA can be predicted with moderate performance using SVR and NDSI preprocessing (RMSE = 0.19%, R2 = 0.525). This study demonstrates that hyperspectral imaging data and NDSI preprocessing have the potential to be a method for grading wine grapes for producing quality wines.},
DOI = {10.3390/rs16101655}
}



@article{grape_2,
title = {Investigating the applicability of a snapshot Computed Tomography Imaging Spectrometer for the prediction of °Brix and pH of grapes},
journal = {Spectrochimica Acta Part A: Molecular and Biomolecular Spectroscopy},
volume = {336},
pages = {126017},
year = {2025},
issn = {1386-1425},
doi = {https://doi.org/10.1016/j.saa.2025.126017},
url = {https://www.sciencedirect.com/science/article/pii/S1386142525003233},
author = {Mads Svanborg Peters and Mads Juul Ahlebæk and Mads Toudal Frandsen and Bjarke Jørgensen and Christian Hald Jessen and Andreas Krogh Carlsen and Morten Sielnik Andersen and Wei-Chih Huang and René Lynge Eriksen},
keywords = {Hyperspectral imaging (HSI), Computed Tomography Imaging Spectrometer (CTIS), Partial Least Squares Regression (PLSR), Grape quality assessment, Snapshot hyperspectral imaging},
abstract = {This study compares the performance of a newly developed snapshot hyperspectral imaging (HSI) system based on Computed Tomography Imaging Spectroscopy (CTIS) and a state-of-the-art line scan HSI system for determining soluble solids content (°Brix) and pH values in four table grape cultivars (Sheegene 20, Sugrathirteen, Grapaes, and Sweet Flavor). A total of 318 grapes were imaged and predictions were validated against reference measurements obtained with a refractometer (°Brix) and a pH meter (pH). For the line scan system, Partial Least Squares Regression (PLSR) models based on the full spectral range demonstrated excellent performance with RMSEPBrix=0.63, RMSEPpH=0.09, RBrix2=0.94, and RpH2=0.79. Reducing the spectral range led to a decline in performance, with RMSEPBrix=1.29 and RMSEPpH=0.12, and RBrix2=0.76 and RpH2=0.69. The CTIS system, despite its narrower spectral range, achieved comparable performance with U-Net reconstructions (RMSEPBrix=1.35, RMSEPpH=0.012, RBrix2=0.74, RpH2=0.70). The CTIS system’s key advantages—such as its lower cost, portability, and ability to capture snapshot hyperspectral images—make it a viable option for in-field applications in grape quality assessment. This study highlights the potential for CTIS-based systems to complement traditional line scan systems, particularly in real-world, out-of-laboratory settings.}
}
@article{iN_Field_white_reference, title={Characterization of a Field Spectroradiometer for Unattended Vegetation Monitoring. Key Sensor Models and Impacts on Reflectance}, volume={15}, ISSN={1424-8220}, url={https://dx.doi.org/10.3390/s150204154}, DOI={10.3390/s150204154}, number={2}, journal={Sensors}, publisher={Sensors}, author={Pacheco-Labrador, Javier and Martín, M.}, year={2015}, pages={4154–4175} }
@article{IAR,
title = {Atmospheric correction algorithms for hyperspectral remote sensing data of land and ocean},
journal = {Remote Sensing of Environment},
volume = {113},
pages = {S17-S24},
year = {2009},
note = {Imaging Spectroscopy Special Issue},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2007.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S0034425709000741},
author = {Bo-Cai Gao and Marcos J. Montes and Curtiss O. Davis and Alexander F.H. Goetz},
keywords = {Hyperspectral, Imaging spectrometer, Atmospheric correction, Remote sensing, AVIRIS},
abstract = {Hyperspectral imaging data have been collected with different types of imaging spectrometers from aircraft and satellite platforms since the mid-1980s. Because the solar radiation on the sun-surface-sensor path in the 0.4–2.5 µm visible and near-IR spectral regions is subject to absorption and scattering by atmospheric gases and aerosols, the hyperspectral imaging data contains atmospheric effects. In order to use hyperspectral imaging data for quantitative remote sensing of land surfaces and ocean color, the atmospheric effects must be removed. Over the years, atmospheric correction algorithms have evolved from the earlier empirical line method and the flat field method to more recent methods based on rigorous radiative transfer modeling approaches. Here, a review of hyperspectral atmospheric correction techniques is presented. Issues related to spectral smoothing are discussed. Suggestions for improvements to the present atmospheric correction algorithms, mainly the addition of a module for modeling atmospheric nitrogen dioxide absorption effects in the visible, are given.}
}
@article{LOGSEP,
title = {Illumination compensation in ground based hyperspectral imaging},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {129},
pages = {162-178},
year = {2017},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2017.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0924271617302368},
author = {Alexander Wendel and James Underwood},
keywords = {Hyperspectral, Atmospheric correction, Illumination compensation, Reflectance retrieval, Ground based, Robotics},
abstract = {Hyperspectral imaging has emerged as an important tool for analysing vegetation data in agricultural applications. Recently, low altitude and ground based hyperspectral imaging solutions have come to the fore, providing very high resolution data for mapping and studying large areas of crops in detail. However, these platforms introduce a unique set of challenges that need to be overcome to ensure consistent, accurate and timely acquisition of data. One particular problem is dealing with changes in environmental illumination while operating with natural light under cloud cover, which can have considerable effects on spectral shape. In the past this has been commonly achieved by imaging known reference targets at the time of data acquisition, direct measurement of irradiance, or atmospheric modelling. While capturing a reference panel continuously or very frequently allows accurate compensation for illumination changes, this is often not practical with ground based platforms, and impossible in aerial applications. This paper examines the use of an autonomous unmanned ground vehicle (UGV) to gather high resolution hyperspectral imaging data of crops under natural illumination. A process of illumination compensation is performed to extract the inherent reflectance properties of the crops, despite variable illumination. This work adapts a previously developed subspace model approach to reflectance and illumination recovery. Though tested on a ground vehicle in this paper, it is applicable to low altitude unmanned aerial hyperspectral imagery also. The method uses occasional observations of reference panel training data from within the same or other datasets, which enables a practical field protocol that minimises in-field manual labour. This paper tests the new approach, comparing it against traditional methods. Several illumination compensation protocols for high volume ground based data collection are presented based on the results. The findings in this paper are applicable not only to robotics or agricultural applications, but most very low altitude or ground based hyperspectral sensors operating with natural light.}
}

@techreport{MODTRAN,
  author       = {Berk, A and Bernstein, L S and Robertson, D C},
  title        = {MODTRAN: a moderate resolution model for LOWTRAN. Technical report, 12 May 1986-11 May 1987},
  institution  = {Spectral Sciences, Inc., Burlington, MA (USA)},
  annote       = {This interim technical report describes a new band-model formulation for the LOWTRAN 6 atmospheric transmittance/radiation computer code. Band-model parameters for H/sub 2/O, CO/sub 2/, O/sub 3/, CO, CH/sub 4/, O/sub 2/, and N/sub 2/ were calculated using the 1986 HITRAN line atlas. They were calculated for 1 /cm bins from 0 - 17,900/cm and at five temperatures from 200 to 300K. This transmittance model and associated subroutines were integrated into LOWTRAN 6. The spectral resolution of this new option is better than 5/cm (FWHM). A preliminary version of the code was delivered to AFGL for testing. Validation against FASCOD2 calculations will be the emphasis for the remainder of this effort.},
  url          = {https://www.osti.gov/biblio/5671682},
  place        = {United States},
  year         = {1987},
  month        = {07}}


@article{MODTRANlimitations,
title = {Towards operational atmospheric correction of airborne hyperspectral imaging spectroscopy: Algorithm evaluation, key parameter analysis, and machine learning emulators},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {196},
pages = {386-401},
year = {2023},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2022.11.016},
url = {https://www.sciencedirect.com/science/article/pii/S0924271622003094},
author = {Qu Zhou and Sheng Wang and Nanfeng Liu and Philip A. Townsend and Chongya Jiang and Bin Peng and Wouter Verhoef and Kaiyu Guan},
keywords = {Hyperspectral, Atmospheric correction, Surface reflectance, Radiative transfer modeling, Machine learning},
abstract = {Atmospheric correction of airborne hyperspectral imaging spectroscopy (AHIS) to obtain high-quality surface reflectance is the prerequisite for remote sensing applications. Over the last decades, different atmospheric correction methods have been developed based on radiative transfer models (RTMs), however, the relative performances of different algorithms are unclear. Automated operational atmospheric correction methods to process large-volume AHIS data in a high-accurate and high-throughput manner are still lacking. Therefore, this study proposed an operational atmospheric correction pipeline for deriving surface reflectance from AHIS data. To ensure the accuracy and efficiency of the pipeline, we focused on three specific aspects: (1) selecting a suitable RTM for the development of atmospheric lookup tables (LUTs) by comparing the commercial MODerate resolution atmospheric TRANsmission (MODTRAN) and open-sourced Library for Radiative TRANsfer (LibRadTRAN) models, where the widely-used software, Atmospheric/Topographic Correction for Airborne Imagery (ATCOR), was used as benchmarks; (2) identifying key atmospheric correction parameters and determining suitable sources for parameter retrievals including AHIS, Moderate Resolution Imaging Spectroradiometer (MODIS), and AErosol RObotic NETwork (AERONET); and (3) testing the performance of using machine learning emulators to speed up the RTM-based atmospheric correction. Results indicate that (1) atmospheric correction based on MODTRAN LUTs can produce surface reflectance accurately with mean absolute errors < 0.05 and cosine similarities > 0.98 compared to field measurements, which is comparable to the software ATCOR and slightly outperforms the LibRadTRAN LUTs; (2) sobol global sensitivity analysis demonstrates that in the atmospheric correction, visibility and water vapor are two key parameters that can be accurately derived from AHIS in contrast to MODIS or AERONET data; and (3) Random Forest emulators can produce accurate estimations of surface reflectance with mean absolute errors < 0.03 and cosine similarities > 0.98 for higher processing efficiency and determine a suitable set of wavelengths for retrieving atmospheric visibility and water vapor. The proposed atmospheric correction pipeline also improved the four-stream radiative transfer theory for airborne applications by considering adjacent effects from airborne surrounding pixels and can also be applied for atmospheric correction of hyperspectral data from spaceborne missions.}
}

@INPROCEEDINGS{limitationsIAR,
  author={Gao, B.-C. and Davis, C. and Goetz, A.},
  booktitle={2006 IEEE International Symposium on Geoscience and Remote Sensing}, 
  title={A Review of Atmospheric Correction Techniques for Hyperspectral Remote Sensing of Land Surfaces and Ocean Color}, 
  year={2006},
  volume={},
  number={},
  pages={1979-1981},
  keywords={Hyperspectral sensors;Remote sensing;Land surface;Sea surface;Oceans;Color;Hyperspectral imaging;Spectroscopy;NASA;Propulsion},
  doi={10.1109/IGARSS.2006.512}}

@article{SILLRGAN,
title = {Robust hyperspectral image classification using generative adversarial networks},
journal = {Information Sciences},
volume = {666},
pages = {120452},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120452},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524003657},
author = {Ziru Yu and Wei Cui},
keywords = {Hyperspectral image, Illumination, Generative adversarial networks, Multitask learning, Domain adaptation, Semi-supervised learning},
abstract = {This paper introduces Sill-Rgan, a novel Generative Adversarial Network (GAN) designed to improve hyperspectral image (HSI) classification under varying lighting conditions. Sill-Rgan uniquely maps different light condition domains, enhancing sample classification robustness and generating new virtual samples. Addressing challenges like high spectral dimensionality and noise in HSI classification, our approach utilizes a deep proxy-based learning framework. It integrates and improves advanced GAN models and multitask networks for optimal training stability and loss function optimization. The model's mapping network is adept at generating domain-specific latent codes, enabling the transformation of original hyperspectral data into enhanced versions. Extensive experiments conducted on hyperspectral datasets of agricultural products under diverse indoor and outdoor lighting conditions confirm the effectiveness of Sill-Rgan. The results highlight the model's adaptability in both supervised and semi-supervised learning scenarios, yielding exceptional classification accuracy and enhanced data quality. The versatile potential of Sill-Rgan extends its applicability to a broad range of spectral data classifications, underlining its significant contribution to hyperspectral imaging. This advancement opens new avenues in machine vision systems, particularly in scenarios with dynamic lighting challenges.}
}

@article{DANN,
  author  = {Yaroslav Ganin and Evgeniya Ustinova and Hana Ajakan and Pascal Germain and Hugo Larochelle and Fran{\c{c}}ois Laviolette and Mario March and Victor Lempitsky},
  title   = {Domain-Adversarial Training of Neural Networks},
  journal = {Journal of Machine Learning Research},
  year    = {2016},
  volume  = {17},
  number  = {59},
  pages   = {1--35},
  url     = {http://jmlr.org/papers/v17/15-239.html}
}
@unknown{physicalInformedVAE,
author = {Thoreau, Romain and Risser, Laurent and Achard, Véronique and Berthelot, Beatrice and Briottet, Xavier},
year = {2022},
month = {10},
pages = {},
title = {Physics-informed Variational Autoencoders for Improved Robustness to Environmental Factors of Variation},
doi = {10.48550/arXiv.2210.10418}
}

@misc{SPECIMFX,
  title = {{SPECIM}},
  howpublished = {\url{https://www.specim.com/}},
  note = {Accessed: 2025-06-25}
}
@article{manifoldREG,
  author  = {Mikhail Belkin and Partha Niyogi and Vikas Sindhwani},
  title   = {Manifold  Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples},
  journal = {Journal of Machine Learning Research},
  year    = {2006},
  volume  = {7},
  number  = {85},
  pages   = {2399--2434},
  url     = {http://jmlr.org/papers/v7/belkin06a.html}
}
@inproceedings{biClassifier,
 author = {Bousmalis, Konstantinos and Trigeorgis, George and Silberman, Nathan and Krishnan, Dilip and Erhan, Dumitru},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Domain Separation Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2016/file/45fbc6d3e05ebd93369ce542e8f2322d-Paper.pdf},
 volume = {29},
 year = {2016}
}
@article{tsne,
  author  = {Laurens van der Maaten and Geoffrey Hinton},
  title   = {Visualizing Data using t-SNE},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  volume  = {9},
  number  = {86},
  pages   = {2579--2605},
  url     = {http://jmlr.org/papers/v9/vandermaaten08a.html}
}
@inproceedings{dataAug1, title={Conditional generative adversarial network for synthesizing hyperspectral images of breast cancer cells from digitized histology}, DOI={10.1117/12.2549994}, author={Halicek, Martin and Ortega, Samuel and Fabelo, Himar and Lopez, Carlos and Lejaune, Marylene and Callico, Gustavo M. and Fei, Baowei}, year={2020}, pages={29} }
@Article{dataAug2,
AUTHOR = {Wang, Wenning and Liu, Xuebin and Mou, Xuanqin},
TITLE = {Data Augmentation and Spectral Structure Features for Limited Samples Hyperspectral Classification},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {547},
URL = {https://www.mdpi.com/2072-4292/13/4/547},
ISSN = {2072-4292},
ABSTRACT = {For both traditional classification and current popular deep learning methods, the limited sample classification problem is very challenging, and the lack of samples is an important factor affecting the classification performance. Our work includes two aspects. First, the unsupervised data augmentation for all hyperspectral samples not only improves the classification accuracy greatly with the newly added training samples, but also further improves the classification accuracy of the classifier by optimizing the augmented test samples. Second, an effective spectral structure extraction method is designed, and the effective spectral structure features have a better classification accuracy than the true spectral features.},
DOI = {10.3390/rs13040547}
}

@incollection{sunspectrum,
title = {Chapter 1 - Principles of photocatalysis},
editor = {Jiaguo Yu and Liuyang Zhang and Linxi Wang and Bicheng Zhu},
series = {Interface Science and Technology},
publisher = {Elsevier},
volume = {35},
pages = {1-52},
year = {2023},
booktitle = {S-scheme Heterojunction Photocatalysts},
issn = {1573-4285},
doi = {https://doi.org/10.1016/B978-0-443-18786-5.00002-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443187865000020},
author = {Linxi Wang and Jiaguo Yu},
keywords = {Carbon dioxide reduction, Hydrogen peroxide production, Organic synthesis, Photocatalysis, Photocatalysts, Photocatalytic principles, Pollutant degradation, Water splitting},
abstract = {Photocatalysis is an important ramification of catalysis which generates charge carriers under light irradiation to catalyze chemical reactions. Photocatalysis mimics the natural photosynthesis process, which is driven by the clean and inexhaustible sunlight. Besides, photocatalytic reactions operate at ambient temperatures and pressures, greatly reducing the requirements for reaction facilities as well as the operating cost. Owing to these unique advantages, photocatalysis powered by the renewable solar energy is deemed as an ideal pathway for industrial production, which can greatly decrease the reliance on fossil fuels to alleviate energy crisis and the greenhouse effect. As a result, photocatalysis has been applied in many crucial reactions, such as H2 production via water splitting, CO2 photoreduction to renewable chemical fuels, photodegradation of pollutants, N2 fixation, H2O2 production, sterilization, organic synthesis, etc. However, photocatalysis suffers from low product yields due to the rapid recombination of photogenerated charge carriers and lack of redox abilities. Thus, the design and development of novel photocatalysts are paramount to address these issues and improve the photocatalytic performance. In this chapter, we will systematically introduce the fundamentals of photocatalysis, including the historical evolvement, the principles of a photocatalytic process, different classes of photocatalysts, and the application of photocatalysis in various reactions. We anticipate that readers will grasp basic understanding of photocatalysis and photocatalysts.}
}
@article{savgolFilter,
title = {Derivative Analysis of Hyperspectral Data},
journal = {Remote Sensing of Environment},
volume = {66},
number = {1},
pages = {41-51},
year = {1998},
issn = {0034-4257},
doi = {https://doi.org/10.1016/S0034-4257(98)00032-7},
url = {https://www.sciencedirect.com/science/article/pii/S0034425798000327},
author = {Fuan Tsai and William Philpot},
abstract = {With the goal of applying derivative spectral analysis to analyze high-resolution, spectrally continuous remote sensing data, several smoothing and derivative computation algorithms have been reviewed and modified to develop a set of cross-platform spectral analysis tools. Emphasis was placed on exploring different smoothing and derivative algorithms to extract spectral details from spectral data sets. A modular program was created to perform interactive derivative analysis. This module calculated derivatives using either a convolution (Savitzky–Golay) or finite divided difference approximation algorithm. Spectra were smoothed using one of the three built-in smoothing algorithms (Savitzky–Golay smoothing, Kawata–Minami smoothing, and mean-filter smoothing) prior to the derivative computation procedures. Laboratory spectral data were used to test the performance of the implemented derivative analysis module. An algorithm for detecting the absorption band positions was executed on synthetic spectra and a soybean fluorescence spectrum to demonstrate the usage of the implemented modules in extracting spectral features. Issues related to smoothing and spectral deviation caused by the smoothing or derivative computation algorithms were also observed and are discussed. A scaling effect, resulting from the migration of band separations when using the finite divided difference approximation derivative algorithm, can be used to enhance spectral features at the scale of specified sampling interval and remove noise or features smaller than the sampling interval.}
}
@article{hsigrape0,
title = {Precision viticulture: Automatic selection of the regions of interest from moving wagon hyperspectral images of grapes for efficient SSC prediction},
journal = {Smart Agricultural Technology},
volume = {7},
pages = {100434},
year = {2024},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2024.100434},
url = {https://www.sciencedirect.com/science/article/pii/S277237552400039X},
author = {Alessandro Benelli and Chiara Cevoli and Angelo Fabbri and Søren Balling Engelsen and Klavs Martin Sørensen},
keywords = {Hyperspectral imaging, Grape, Automatic, Classification, PLS-DA, PLS},
abstract = {Precision viticulture is increasingly being applied to automate and optimize grape production in the vineyard. This paper describes the development of a method for automatic selection of regions of interest from hyperspectral images obtained of a row of vines and intended for prediction of soluble solids content. For this purpose, a dataset consisting of hyperspectral images of a row of ‘Sangiovese’ wine grapes was adopted. Hyperspectral images were acquired directly in the field by means of a hyperspectral imaging Vis/NIR system (400–1000 nm) mounted on a ground-based vehicle. The analyses were carried out on 17 different days, under clear or partly cloudy conditions, in the period between post-veraison and harvest. The vineyard row of Sangiovese vines was divided into 11 sections and a hyperspectral image for each section for each day of analysis was acquired. The regions of interest of the hyperspectral images, comprising the areas representing the grapes, were selected using a PLS-DA-based method. The best PLS-DA model provided excellent results, with sensitivity and specificity values of 0.991 and 0.996, respectively. The mean spectra of the selected regions of interest (ROI) were finally used to predict the soluble solids content (SSC) of the grapes by PLS regression to a primary reference analysis. The results of SSC predictions using the automatic selection of ROIs (R2CV = 0.74 and RMSECV = 0.86 °Brix) were on par with similar regression based on carefully manual selection of ROIs (R2CV = 0.73 and RMSECV = 0.87 °Brix).}
}
@article{Axel,
author = {Willekens, Axel and Temmerman, Sébastien and Wyffels, Francis and Pieters, Jan and Cool, Simon},
year = {2025},
month = {06},
pages = {n/a-n/a},
title = {Development of an Agricultural Robot Taskmap Operation Framework},
journal = {Journal of Field Robotics},
doi = {10.1002/rob.70003}
}

@misc{yolo,
author = {Jocher, Glenn and Qiu, Jing and Chaurasia, Ayush},
license = {AGPL-3.0},
month = jan,
title = {{Ultralytics YOLO}},
url = {https://github.com/ultralytics/ultralytics},
version = {8.0.0},
year = {2023}
}

@Article{laborIntensive,
AUTHOR = {Ammoniaci, Marco and Kartsiotis, Simon-Paolo and Perria, Rita and Storchi, Paolo},
TITLE = {State of the Art of Monitoring Technologies and Data Processing for Precision Viticulture},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {201},
URL = {https://www.mdpi.com/2077-0472/11/3/201},
ISSN = {2077-0472},
ABSTRACT = {Precision viticulture (PV) aims to optimize vineyard management, reducing the use of resources, the environmental impact and maximizing the yield and quality of the production. New technologies as UAVs, satellites, proximal sensors and variable rate machines (VRT) are being developed and used more and more frequently in recent years thanks also to informatics systems able to read, analyze and process a huge number of data in order to give the winegrowers a decision support system (DSS) for making better decisions at the right place and time. This review presents a brief state of the art of precision viticulture technologies, focusing on monitoring tools, i.e., remote/proximal sensing, variable rate machines, robotics, DSS and the wireless sensor network.},
DOI = {10.3390/agriculture11030201}
}
@article{agriculture4,
title = {The digitization of agricultural industry – a systematic literature review on agriculture 4.0},
journal = {Smart Agricultural Technology},
volume = {2},
pages = {100042},
year = {2022},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2022.100042},
url = {https://www.sciencedirect.com/science/article/pii/S2772375522000090},
author = {Rabiya Abbasi and Pablo Martinez and Rafiq Ahmad},
keywords = {Agriculture 4.0, Industry 4.0, Digitization, Connectivity, Internet of things, Smart agricultural systems},
abstract = {Agriculture is considered one of the most important sectors that play a strategic role in ensuring food security. However, with the increasing world's population, agri-food demands are growing — posing the need to switch from traditional agricultural methods to smart agriculture practices, also known as agriculture 4.0. To fully benefit from the potential of agriculture 4.0, it is significant to understand and address the problems and challenges associated with it. This study, therefore, aims to contribute to the development of agriculture 4.0 by investigating the emerging trends of digital technologies in the agricultural industry. For this purpose, a systematic literature review based on Protocol of Preferred Reporting Items for Systematic Reviews and Meta-Analyses is conducted to analyse the scientific literature related to crop farming published in the last decade. After applying the protocol, 148 papers were selected and the extent of digital technologies adoption in agriculture was examined in the context of service type, technology readiness level, and farm type. The results have shown that digital technologies such as autonomous robotic systems, internet of things, and machine learning are significantly explored and open-air farms are frequently considered in research studies (69%), contrary to indoor farms (31%). Moreover, it is observed that most use cases are still in the prototypical phase. Finally, potential roadblocks to the digitization of the agriculture sector were identified and classified at technical and socio-economic levels. This comprehensive review results in providing useful information on the current status of digital technologies in agriculture along with prospective future opportunities.}
}

@article{Lyu2024, title={Hyperspectral Imaging Spectroscopy for Non-Destructive Determination of Grape Berry Total Soluble Solids and Titratable Acidity}, volume={16}, ISSN={2072-4292}, DOI={10.3390/rs16101655}, number={10}, journal={Remote Sensing}, publisher={Remote Sensing}, author={Lyu, Hongyi and Grafton, Miles and Ramilan, Thiagarajah and Irwin, Matthew and Sandoval, Eduardo}, year={2024}, pages={1655} }
@article{SanRoman2024,
title = {Use of the hyperspectral imaging to estimate the volatile composition of Tempranillo grape berries during ripening},
journal = {Scientia Horticulturae},
volume = {337},
pages = {113537},
year = {2024},
issn = {0304-4238},
doi = {https://doi.org/10.1016/j.scienta.2024.113537},
url = {https://www.sciencedirect.com/science/article/pii/S0304423824006939},
author = {Sandra {Marín-San Román} and María Paz Diago and Juan Fernández-Novales and Cristina Cebrián-Tarancón and M. Rosario Salinas and Teresa Garde-Cerdán},
keywords = {Aromatic composition, Non-invasive, TF-SPME, Chemometrics, Maturity monitoring},
abstract = {Volatile compounds present in grapes, and accumulated during the ripening process, are responsible for providing wine its main aromatic characteristics. However, there is currently no feasible and inexpensive method to monitor the volatile composition of grape berries during ripening. In recent years, hyperspectral imaging (HSI) has received wide recognition as a non-destructive and rapid technique for quality assessment in the agri-food industry. In this work, we have studied the use of HSI to estimate the volatile composition throughout ripening in berries of Vitis vinifera L. Tempranillo. For this purpose, 240 spectra in the visible-short wave near infrared (VIS+SW-NIR) range (400–1000 nm) were acquired from intact grapes in a laboratory. The reference method used was thin film solid phase microextraction - gas chromatography - mass spectrometry (TF-SPME-GC-MS). Using this instrumental method, a total of 20 volatile compounds were quantified. Total soluble solids (TSS) were also determined and refractometry was used as the reference method. With the reference and spectral data, calibration model using modified partial least squares (MPLS) regression, and external prediction were built. Values of determination coefficient of cross validation (R2CV) ≥ 0.5 were obtained for all individual compounds except for α-terpineol, benzaldehyde, and (E)-2-hexen-1-ol. From these results, it can be affirmed that HSI in the VIS+SW-NIR range is an appropriate non-destructive tool to differentiate between high and low values of each volatile compound throughout the ripening of Tempranillo grape berries in a rapid and contactless way.}
}

@article{Gabrielli2023, title={Hyperspectral imaging to assess wine grape quality}, volume={3}, ISSN={2573-5098}, DOI={10.1002/jsf2.150}, number={10}, journal={JSFA reports}, publisher={JSFA reports}, author={Gabrielli, Mario and Ounaissi, Daoud and Lançon‐Verdier, Vanessa and Julien, Séverine and Le Meurlay, Dominique and Maury, Chantal}, year={2023}, pages={452–462} }
@article{Gomes2021, title={Application of Hyperspectral Imaging and Deep Learning for Robust Prediction of Sugar and pH Levels in Wine Grape Berries}, volume={21}, ISSN={1424-8220}, DOI={10.3390/s21103459}, number={10}, journal={Sensors}, publisher={Sensors}, author={Gomes, Véronique and Mendes-Ferreira, Ana and Melo-Pinto, Pedro}, year={2021}, pages={3459} }

@article{Ref_1D_CNN,
title = {1D convolutional neural networks and applications: A survey},
journal = {Mechanical Systems and Signal Processing},
volume = {151},
pages = {107398},
year = {2021},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2020.107398},
url = {https://www.sciencedirect.com/science/article/pii/S0888327020307846},
author = {Serkan Kiranyaz and Onur Avci and Osama Abdeljaber and Turker Ince and Moncef Gabbouj and Daniel J. Inman},
keywords = {Artificial Neural Networks, Machine learning, Deep learning, Convolutional neural networks, Structural health monitoring, Condition monitoring, Arrhythmia detection and identification, Fault detection, Structural damage detection},
abstract = {During the last decade, Convolutional Neural Networks (CNNs) have become the de facto standard for various Computer Vision and Machine Learning operations. CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and millions of parameters have the ability to learn complex objects and patterns providing that they can be trained on a massive size visual database with ground-truth labels. With a proper training, this unique ability makes them the primary tool for various engineering applications for 2D signals such as images and video frames. Yet, this may not be a viable option in numerous applications over 1D signals especially when the training data is scarce or application specific. To address this issue, 1D CNNs have recently been proposed and immediately achieved the state-of-the-art performance levels in several applications such as personalized biomedical data classification and early diagnosis, structural health monitoring, anomaly detection and identification in power electronics and electrical motor fault detection. Another major advantage is that a real-time and low-cost hardware implementation is feasible due to the simple and compact configuration of 1D CNNs that perform only 1D convolutions (scalar multiplications and additions). This paper presents a comprehensive review of the general architecture and principals of 1D CNNs along with their major engineering applications, especially focused on the recent progress in this field. Their state-of-the-art performance is highlighted concluding with their unique properties. The benchmark datasets and the principal 1D CNN software used in those applications are also publicly shared in a dedicated website. While there has not been a paper on the review of 1D CNNs and its applications in the literature, this paper fulfills this gap.}
}

@inproceedings{Ref_2D_CNN,
 author = {LeCun, Yann and Boser, Bernhard and Denker, John and Henderson, Donnie and Howard, R. and Hubbard, Wayne and Jackel, Lawrence},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Touretzky},
 pages = {},
 publisher = {Morgan-Kaufmann},
 title = {Handwritten Digit Recognition with a Back-Propagation Network},
 url = {https://proceedings.neurips.cc/paper_files/paper/1989/file/53c3bce66e43be4f209556518c2fcb54-Paper.pdf},
 volume = {2},
 year = {1989}
}
@inproceedings{
Ref_Vision_Transformer,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}
@misc{yolo8,
  author = {Glenn Jocher and Ayush Chaurasia and Jing Qiu},
  title = {Ultralytics YOLOv8},
  version = {8.0.0},
  year = {2023},
  url = {https://github.com/ultralytics/ultralytics},
  orcid = {0000-0001-5950-6979, 0000-0002-7603-6750, 0000-0003-3783-7069},
  license = {AGPL-3.0}
}
@article{yolo9,
  title={YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information},
  author={Wang, Chien-Yao  and Liao, Hong-Yuan Mark},
  booktitle={arXiv preprint arXiv:2402.13616},
  year={2024}
}
@article{yolo10,
  title={YOLOv10: Real-Time End-to-End Object Detection},
  author={Ao Wang and Hui Chen and Lihao Liu and others},
  journal={arXiv preprint arXiv:2405.14458},
  year={2024},
  institution={Tsinghua University},
  license = {AGPL-3.0}
}
@misc{yolo11,
  author = {Glenn Jocher and Jing Qiu},
  title = {Ultralytics YOLO11},
  version = {11.0.0},
  year = {2024},
  url = {https://github.com/ultralytics/ultralytics},
  orcid = {0000-0001-5950-6979, 0000-0003-3783-7069},
  license = {AGPL-3.0}
}
@article{yolo12,
  title={YOLOv12: Attention-Centric Real-Time Object Detectors},
  author={Tian, Yunjie and Ye, Qixiang and Doermann, David},
  journal={arXiv preprint arXiv:2502.12524},
  year={2025}
}

@misc{rtdetrv2,
      title={RTDETRv2: All-in-One Detection Transformer Beats YOLO and DINO},
      author={Wenyu Lv and Yian Zhao and Qinyao Chang and Kui Huang and Guanzhong Wang and Yi Liu},
      year={2024},
      eprint={2407.17140},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{GAN,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1406.2661}, 
}
@misc{VAE,
      title={Auto-Encoding Variational Bayes}, 
      author={Diederik P Kingma and Max Welling},
      year={2022},
      eprint={1312.6114},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1312.6114}, 
}
@inbook{AE,
author = {Rumelhart, D. E. and Hinton, G. E. and Williams, R. J.},
title = {Learning internal representations by error propagation},
year = {1986},
isbn = {026268053X},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
booktitle = {Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol. 1: Foundations},
pages = {318–362},
numpages = {45}
}
@misc{GRL,
      title={Unsupervised Domain Adaptation by Backpropagation}, 
      author={Yaroslav Ganin and Victor Lempitsky},
      year={2015},
      eprint={1409.7495},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1409.7495}, 
}

@article{extraChemicals,
title = {Monitoring the effects and side-effects on wine colour and flavonoid composition of the combined post-fermentative additions of seeds and mannoproteins},
journal = {Food Research International},
volume = {126},
pages = {108650},
year = {2019},
issn = {0963-9969},
doi = {https://doi.org/10.1016/j.foodres.2019.108650},
url = {https://www.sciencedirect.com/science/article/pii/S0963996919305368},
author = {Cristina Alcalde-Eon and Rebeca Ferreras-Charro and Raúl Ferrer-Gallego and Francisco J. Rivero and Francisco J. Heredia and María Teresa Escribano-Bailón},
keywords = { L. Syrah, Pedro Ximénez, Grape seeds, Mannoproteins, CIELAB, HPLC-DAD-MS, Flavanols, Flavonols, Anthocyanins, Colloidal stability},
abstract = {One of the main consequences of the advancement of harvest date associated to global climate change is that the phenolic maturity of grapes can be delayed in relation to their technological maturity. As a consequence, wines made from these grapes can be poor in phenolic compounds or possess an unbalanced phenolic composition, affecting their global quality. The combined post-fermentative addition of seeds and an astringency-modulator mannoprotein (MP) might be a potential strategy to solve this problem, since seeds might supply flavanols and improve wine chemical stability and the mannoprotein might modulate the changes induced in astringency by the addition of seeds and improve wine colloidal stability. The present study aimed at monitoring at different moments of winemaking and ageing the effects and side-effects of this combined strategy on the detailed flavanol, flavonol and anthocyanin compositions and on colour of wines made from Syrah grapes. Seeds were obtained from Pedro Ximénez overripe grapes. Flavanol composition and flavonol and anthocyanin compositions were determined by HPLC-MSn-MRM and HPLC-DAD-MSn analyses, respectively. Colour changes caused by these additions were studied from CIELAB parameters as well as the ability of these techniques to protect colour from bleaching agents, such as SO2. In general, the addition of seeds initially increased the levels of flavanols and anthocyanins. However, during bottle ageing a reduction in the levels of flavanols, flavonols and anthocyanins could be observed in seed treated wines, which might be related to the greater formation of flavanol aggregates associated with greater levels of flavanols. This effect was partially solved for most of the flavonoids studied with the additional MP treatment. Treated and control wines showed colour differences that were visible to human eye, although they were reduced over time. At the end of the study, treated wines showed colour parameters corresponding to younger wines than those observed in control wines. A greater resistance against SO2 bleaching was also observed in treated wines, which can be mainly associated to the greater percentages of polymeric pigments caused by seed treatment and to the improvement of the colloidal stability of SO2-resistant pigments caused by the addition of the MP.}
}

@misc{wandb,
title = {Experiment Tracking with Weights and Biases},
year = {2020},
note = {Software available from wandb.com},
url={https://www.wandb.com/},
author = {Biewald, Lukas},
}
@article{redEdge, title={Evaluation of Sentinel-2 Red-Edge Bands for Empirical Estimation of Green LAI and Chlorophyll Content}, volume={11}, ISSN={1424-8220}, url={https://dx.doi.org/10.3390/s110707063}, DOI={10.3390/s110707063}, number={7}, journal={Sensors}, publisher={Sensors}, author={Delegido, Jesús and Verrelst, Jochem and Alonso, Luis and Moreno, José}, year={2011}, pages={7063–7081} }


@article{MMD,
  author  = {Arthur Gretton and Karsten M. Borgwardt and Malte J. Rasch and Bernhard Sch{{\"o}}lkopf and Alexander Smola},
  title   = {A Kernel Two-Sample Test},
  journal = {Journal of Machine Learning Research},
  year    = {2012},
  volume  = {13},
  number  = {25},
  pages   = {723-773},
  url     = {http://jmlr.org/papers/v13/gretton12a.html}
}

@ARTICLE{svm,
  author={Hearst, M.A. and Dumais, S.T. and Osuna, E. and Platt, J. and Scholkopf, B.},
  journal={IEEE Intelligent Systems and their Applications}, 
  title={Support vector machines}, 
  year={1998},
  volume={13},
  number={4},
  pages={18-28},
  keywords={Support vector machines;Machine learning;Algorithm design and analysis;Pattern recognition;Neural networks;Training data;Polynomials;Kernel;Character recognition;Web pages},
  doi={10.1109/5254.708428}}

@article{red_wine, title={Measurements of reflectance and fluorescence spectra for nondestructive characterizing ripeness of grapevine berries}, volume={54}, ISSN={0300-3604}, DOI={10.1007/s11099-015-0163-9}, number={1}, journal={Photosynthetica}, publisher={Photosynthetica}, author={Navrátil, M. and Buschmann, C.}, year={2016}, pages={101–109} }








