# LISA – Hyperspectral Vineyard Pipeline

LISA bundles the code that accompanies the grape quality monitoring paper. The repository contains the full processing pipeline, pre-trained models, and supporting artefacts used to generate spatial maps of grape bunch quality from hyperspectral captures.

## Highlights

- End-to-end processing pipeline with YOLO-based bunch detection, weight prediction, and quality estimation.
- Ready-to-use pretrained weights stored under `models/` for reproducible results.
- CLI for batch processing single folders or continuously watching for new captures.
- Example outputs in `results/` and the full manuscript PDF (`_Ciem__Hyperspectral_grape_monitoring___IoT_journal.Final.pdf`).

## Quickstart

1. Create and activate an environment (Python ≥ 3.10 recommended):
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Windows: .venv\Scripts\activate
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. (Optional, recommended) Install the project in editable mode to expose the `lisa` console entry point:
   ```bash
   pip install -e .
   ```

## Usage

Process an individual capture folder:
```bash
python main.py process-folder data/my_capture --update-log
```

Watch the default `data/` directory and process any new folders once:
```bash
python main.py watch --run-once
```

Additional options:
- `--legacy-rgb` switches to the historic visualization used in earlier experiments.
- `--confidence 0.25` customises the YOLO detection confidence.
- `--show-fig` opens the generated annotated map after processing.

See `python main.py --help` (or `lisa --help` after editable installation) for the full CLI reference.

## Repository Layout

- `main.py` – lightweight entry point delegating to the new CLI.
- `src/lisa/` – reusable library code (config, asset loading, runtime helpers, CLI).
- `src/pipeline.py` and `src/utilities.py` – core modelling logic from the research codebase.
- `models/` – pretrained weights and cached artefacts referenced by the pipeline.
- `results/` – sample annotated maps generated by the pipeline (e.g. `results/20250926_FX10_sweep_voorkant_2025-09-26_13-32-49.png`).
- `relevantInformation/` – paper resources that may migrate to an external archive later.
- `demoTest.ipynb` – exploratory notebook using the legacy APIs.

## Demo Scripts

- `run_demo.sh`
- `run_demo.bat`

Both scripts activate `venv/` when present and execute `python main.py watch --run-once`. Populate `data/` with a capture folder to try the pipeline locally.

## Paper

The manuscript is stored at `_Ciem__Hyperspectral_grape_monitoring___IoT_journal.Final.pdf`. Supporting LaTeX sources live under `relevantInformation/`.

## Notes

- Model checkpoints (`.pth`, `.pkl`) are sizeable; keep them in Git LFS if the repository footprint grows.
- CUDA is supported for faster inference, but the pipeline runs on CPU as well.
- When the `relevantInformation/` folder moves elsewhere, update the README links accordingly.

Happy experimenting!
