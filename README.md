# LISA – Hyperspectral Vineyard Pipeline

LISA bundles the code that accompanies the grape quality monitoring paper. The repository contains the full processing pipeline, pre-trained models, and supporting artefacts used to generate spatial maps of grape bunch quality from hyperspectral captures.

## Highlights

- End-to-end processing pipeline with YOLO-based bunch detection, weight prediction, and quality estimation.
- Ready-to-use pretrained weights stored under `models/` for reproducible results.
- CLI for batch processing single folders or continuously watching for new captures.
- Lightweight Python package (`lisa`) with reusable helpers for custom tooling.
- Example outputs in `results/` and the full manuscript PDF (`_Ciem__Hyperspectral_grape_monitoring___IoT_journal.Final.pdf`).

## Quickstart

1. Create and activate an environment (Python ≥ 3.10 recommended):
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Windows: .venv\Scripts\activate
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. (Optional, recommended) Install the project in editable mode to expose the `lisa` console entry point:
   ```bash
   pip install -e .
   ```

## Sample Data

The hyperspectral captures are large (several GB per sweep), so the repository keeps the `data/` folder empty by default. Host the demo capture externally (e.g. Azure Blob, Hugging Face Hub, S3) and provide a direct download link.

1. Export a small representative capture folder as `sample_capture.tar.gz` (include the `capture/*.hdr` and `capture/*.raw` files).
2. A ready-to-use sample is hosted at [cloud.ilabt.imec.be](https://cloud.ilabt.imec.be/index.php/s/5z7pC8Dwt7LfHWL) with the direct download link `https://cloud.ilabt.imec.be/index.php/s/5z7pC8Dwt7LfHWL/download`.
3. Download and extract via the helper script:
   ```bash
   bash scripts/download_sample_data.sh
   ```
   The script fetches the archive, extracts it into `data/sample_capture`, and cleans up the tarball. Update the URL once the hosting location is final.

## Usage

Process an individual capture folder:
```bash
python main.py process-folder data/my_capture --update-log
```

Watch the default `data/` directory and process any new folders once:
```bash
python main.py watch --run-once
```

Additional options:
- `--legacy-rgb` switches to the historic visualization used in earlier experiments.
- `--confidence 0.25` customises the YOLO detection confidence.
- `--show-fig` opens the generated annotated map after processing.

See `python main.py --help` (or `lisa --help` after editable installation) for the full CLI reference.

## Repository Layout

- `main.py` – lightweight entry point delegating to the new CLI.
- `src/lisa/` – reusable library code (config, asset loading, runtime helpers, CLI).
- `src/lisa/inference.py` – modernised inference utilities (object tracking, sliding window, loaders).
- `src/lisa/visualization.py` – helpers for rendering annotated overview maps.
- `src/pipeline.py` and `src/utilities.py` – core modelling logic from the research codebase.
- `models/` – pretrained weights and cached artefacts referenced by the pipeline.
- `results/` – sample annotated maps generated by the pipeline (e.g. `results/20250926_FX10_sweep_voorkant_2025-09-26_13-32-49.png`).
- `relevantInformation/` – paper resources that may migrate to an external archive later.
- `demoTest.ipynb` – exploratory notebook using the legacy APIs.
- `scripts/` – helper utilities such as `scripts/download_sample_data.sh`.

## Demo Scripts

- `run_demo.sh`
- `run_demo.bat`

Both scripts activate `venv/` when present and execute `python main.py watch --run-once`. Populate `data/` with a capture folder to try the pipeline locally.

## Architecture Overview

```mermaid
flowchart LR
   A[Capture Folder] --> B[data_finder]
   B --> C[ENVI Loader]
   C --> D[Sliding Window]
   D --> E[YOLO Detection]
   E --> F[Object Tracker]
   F --> G[Weight Estimator]
   F --> H[Quality Model]
   G & H --> I[Result Aggregation]
   I --> J[Annotated Map]
```

## Example Output

![Annotated Sweep](results/20250926_FX10_sweep_voorkant_2025-09-26_13-32-49.png)

## Paper

The manuscript is stored at `_Ciem__Hyperspectral_grape_monitoring___IoT_journal.Final.pdf`. Supporting LaTeX sources live under `relevantInformation/`.

## Notes

- Model checkpoints (`.pth`, `.pkl`) are sizeable; keep them in Git LFS if the repository footprint grows.
- CUDA is supported for faster inference, but the pipeline runs on CPU as well.
- When the `relevantInformation/` folder moves elsewhere, update the README links accordingly.
- `src/pipeline.py` and `src/utilities.py` remain for backwards compatibility; new applications should rely on the `src/lisa` package modules instead.

Happy experimenting!
